* **Name**: Yusuf Bin Musa
* **Matric. Number**: A0218228E
* **Repo Link**: https://github.com/yusufaine/OTOT-A2-A3

---

# Introduction to Kubernetes

## Task A2.1: Deploy a local k8s cluster

To create a local k8s cluster, we would first need the have a configuration for it which can be obtained [here](https://github.com/CS3219-AY2223S1/OTOT-A2-A3/blob/main/k8s/kind/cluster-config.yaml). After which the following command can be used to create and verify the details of the cluster

```bash
# Setting variables, context is set to the newly created kind by default
cname="a2-demo"

# kind create cluster --name <cluster-name> --config <path-to-config>
kind create cluster --name $cname --config ./cluster-config.yaml

# Verify using the following
kubectl cluster-info
kubectl get nodes
```

## Task A2.2: Deploying the A1 Docker image as Deployment in A2.1 cluster

### Applying deployment manifest (`deployment.yaml`)
To deploy the A1 Docker image as deployment into the cluster, we would first need to push it into the docker repository. Logging into Docker is required at this step and can be done with the following command. Do take note of the exposed port of the `dockerfile` as it would need to be specified in `deployment.yaml`.

```bash
# Build the image if that has not been done. The naming convention is suggested as such.
# docker build <path-to-dockerfile> <username/image-name>
docker build . -t yusufaine/nodejs-app

# Push to personal docker repo
docker push yusufaine/nodejs-app:latest
```

After issuing that command, the `deployment.yaml` can be as such
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  labels:
    app: backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
        - name: backend
          image: yusufaine/nodejs-app:latest # pulled from repo
          ports:
            - name: http
              containerPort: 3000 # exposed port from dockerfile
          resources:
            limits:
              cpu: 40m
              memory: 100Mi
```

To apply this configuration and verify that it is applied, the following commands can be issued.

```bash
# kubectl apply -f <path-to-deploy-yaml>
kubectl apply -f ./nodejs-deploy.yaml

# wait for the pods to be ready using any of these commands
# kubectl wait --for=condition=ready pod --selector=app=<label> --timeout=45s
# kubectl get deployment/backend
kubectl get po -l app=backend -w # ctrl-c to stop watching
```

### Applying service manifest (`service.yaml`)

`service.yaml` would then need to be deployed so that the pods within the cluster can be accessed through a singular virtual IP address, akin to reverse proxy. However, the difference here is that said virtual IP address is not exposed to the internet. To circumvent this, using `nginx-ingress-controller` can be used (refer to next section).

```yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: backend
  name: backend-svc
spec:
  selector:
    app: backend
  type: ClusterIP
  ports:
    - name: http
      port: 3000		# exposed from dockerfile
      protocol: TCP
      targetPort: http
```
The following commands can be used to apply and verify the configuration.

```bash
# kubectl apply -f <path-to-svc-yaml>
kubectl apply -f ./nodejs-deploy.yaml

# Print service details
kubectl describe svc backend-svc

# kubectl wait --for=condition=ready pod --selector=app=backend --timeout=45s
kubectl get svc -l app=backend

# In 2 other terminal sessions
# kubectl port-forward service/backend-svc 8080:3000
# curl -s localhost:8080 | grep -E "Metric|Name"
```

### Service verification
![Access via port-forwarding localhost:8080 to the service's port 3000](https://i.ibb.co/MBzgSz1/image.png)

## Task A2.3: Deploy ingress to expose A2.2 to `localhost`

### Creating `nginx-ingress-controller`

Before creating the `nginx-ingress-controller`, which is an abstraction of an L7 load balancer, the cluster would first require node(s) to be labelled with `ingress-ready=true`. If the [provided configuration](https://github.com/CS3219-AY2223S1/OTOT-A2-A3/blob/main/k8s/kind/cluster-config.yaml) was used, this would be true for the first node. Otherwise, it has to be manually labelled.

```bash
# Setting label
# kubectl label node <name> ingress-ready=true

# Verifying if ingress-ready=true
kubectl get nodes -L ingress-ready
```

After which, `nginx-ingress-controller` can then be created.

```bash
# Setting variables
ns="ingress-nginx"
sr="app.kubernetes.io/component=controller"

# Applying nginx ingress config
kubectl apply -f "https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml"

# Verifying 
# kubectl wait --namespace $ns --for=condition=ready pod --selector=$sr --timeout 45s 
# kubectl --namespace $ns get po -l $sr -w
kubectl -n $ns get deploy
```

### Creating ingress object for A1 Docker image

To allow the A1 docker image to be accessible, an ingress object with the appropriate routing rule would then need to be created.

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: backend-ingress
  labels:
    app: backend
spec:
  rules:
    - http:
        paths:
          - path: / # root path to access docker image
            pathType: Prefix
            backend:
              service:
                name: backend-svc
                port:
                  name: http # maps 80 to exposed port
```

This configuration can be applied and verified by issuing the following commands.

```bash
kubectl apply -f nodejs-ingress-obj.yaml
kubectl get ingress -l app=backend
```

After which, `localhost` would be able to serve the A1 Docker image.

![K8s serving A1 dockerfile](https://i.ibb.co/zShH9xS/image.png)
